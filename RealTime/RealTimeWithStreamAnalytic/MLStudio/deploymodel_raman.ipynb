{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1694403123056
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "mlv2\nml_group\neastasia\n956a5d16-ed62-4076-890a-4f7ea58eef95\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694403123846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "# Tip: When model_path is set to a directory, you can use the child_paths parameter to include\n",
        "#      only some of the files from the directory\n",
        "model = Model.register(model_path = \"XGBoost_ramman_model.h5\",\n",
        "                       model_name = \"raman_model_nb\",\n",
        "                       workspace = ws)\n",
        "\n",
        "model = Model.register(model_path = \"scale_raman.h5\",\n",
        "                       model_name = \"scale_raman\",\n",
        "                       workspace = ws)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model raman_model_nb\nRegistering model scale_raman\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694168443060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Create the environment\n",
        "myenv = Environment(name=\"myenv_raman\")\n",
        "conda_dep = CondaDependencies()\n",
        "\n",
        "# Define the packages needed by the model and scripts\n",
        "conda_dep.add_conda_package(\"joblib==1.2.0\")\n",
        "# conda_dep.add_conda_package(\"keras==2.11.0\")\n",
        "conda_dep.add_conda_package(\"numpy==1.24.2\")\n",
        "conda_dep.add_conda_package(\"pandas==1.5.3\")\n",
        "# You must list azureml-defaults as a pip dependency\n",
        "conda_dep.add_pip_package(\"scikit-learn==1.2.1\")\n",
        "# conda_dep.add_pip_package(\"pickle\")\n",
        "\n",
        "conda_dep.add_pip_package(\"scipy==1.10.1\")\n",
        "# conda_dep.add_pip_package(\"tensorflow==2.11.0\")\n",
        "conda_dep.add_pip_package(\"xgboost==1.7.4\")\n",
        "\n",
        "\n",
        "# Adds dependencies to PythonSection of myenv\n",
        "myenv.python.conda_dependencies=conda_dep\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score_raman.py\",\n",
        "                                   environment=myenv)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694403300430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-09-08T12:48:31,894112698+00:00 - rsyslog/run \nbash: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/libtinfo.so.6: no version information available (required by bash)\n2023-09-08T12:48:31,922578689+00:00 - nginx/run \n2023-09-08T12:48:31,930359413+00:00 - gunicorn/run \n2023-09-08T12:48:31,941339248+00:00 | gunicorn/run | \n2023-09-08T12:48:31,952217983+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:31,978219766+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-09-08T12:48:31,987963197+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:31,990749406+00:00 | gunicorn/run | \n2023-09-08T12:48:31,997895029+00:00 | gunicorn/run | \n2023-09-08T12:48:32,006475056+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-09-08T12:48:32,008020361+00:00 | gunicorn/run | \n2023-09-08T12:48:32,009405666+00:00 | gunicorn/run | \n2023-09-08T12:48:32,016698989+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-09-08T12:48:32,018899196+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-09-08T12:48:32,029205429+00:00 | gunicorn/run | \n2023-09-08T12:48:33,562920538+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d\nbase                     /opt/miniconda\n\n2023-09-08T12:48:36,628026102+00:00 | gunicorn/run | \n2023-09-08T12:48:36,634907132+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\nargcomplete==2.1.2\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.29.4\nazure-graphrbac==0.61.1\nazure-identity==1.14.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.3\nazure-mgmt-network==21.0.1\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazureml-core==1.53.0\nazureml-dataprep==4.12.1\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.19.2\nazureml-dataset-runtime==1.53.0\nazureml-defaults==1.53.0\nazureml-inference-server-http==0.8.4.1\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\ncachetools==5.3.1\ncertifi @ file:///croot/certifi_1671487769961/work/certifi\ncffi==1.15.1\ncharset-normalizer==3.2.0\nclick==8.1.7\ncloudpickle==2.2.1\ncontextlib2==21.6.0\ncryptography==41.0.3\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\nFlask==2.2.5\nFlask-Cors==3.0.10\nfusepy==3.0.1\ngoogle-api-core==2.11.1\ngoogle-auth==2.22.0\ngoogleapis-common-protos==1.60.0\ngunicorn==20.1.0\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==6.8.0\nimportlib-resources==6.0.1\ninference-schema==1.5.1\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.1\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work\njsonpickle==3.0.2\njsonschema==4.19.0\njsonschema-specifications==2023.7.1\nknack==0.10.1\nMarkupSafe==2.1.3\nmsal==1.23.0\nmsal-extensions==1.0.0\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy==1.23.5\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==23.0\npandas==1.5.3\nparamiko==3.3.1\npathspec==0.11.2\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nportalocker==2.7.0\nprotobuf==4.24.3\npsutil==5.9.5\npyarrow==11.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser==2.21\npydantic==1.10.12\nPygments==2.16.1\nPyJWT==2.8.0\nPyNaCl==1.5.0\npyOpenSSL==23.2.0\nPySocks==1.7.1\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\npytz @ file:///croot/pytz_1671697431263/work\nPyYAML==6.0.1\nreferencing==0.30.2\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrpds-py==0.10.2\nrsa==4.9\nscikit-learn==1.2.1\nscipy==1.10.1\nSecretStorage==3.3.3\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\ntabulate==0.9.0\nthreadpoolctl==3.2.0\ntyping_extensions==4.7.1\nurllib3==1.26.16\nwebsocket-client==1.6.2\nWerkzeug==2.3.7\nwrapt==1.12.1\nzipp==3.16.2\n\n2023-09-08T12:48:38,124323028+00:00 | gunicorn/run | \n2023-09-08T12:48:38,131432159+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:38,133270467+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-09-08T12:48:38,140750999+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:38,142425406+00:00 | gunicorn/run | \n2023-09-08T12:48:40,863703835+00:00 | gunicorn/run | \n2023-09-08T12:48:40,865375543+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:40,872388076+00:00 | gunicorn/run | AzureML Inference Server\n2023-09-08T12:48:40,874205284+00:00 | gunicorn/run | ###############################################\n2023-09-08T12:48:40,875933592+00:00 | gunicorn/run | \n2023-09-08T12:48:43,655044793+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-09-08 12:48:44,226 I [11] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-09-08 12:48:44,561 I [11] gunicorn.error - Starting gunicorn 20.1.0\n2023-09-08 12:48:44,562 I [11] gunicorn.error - Listening at: http://0.0.0.0:31311 (11)\n2023-09-08 12:48:44,562 I [11] gunicorn.error - Using worker: sync\n2023-09-08 12:48:44,570 I [68] gunicorn.error - Booting worker with pid: 68\n\nAzure ML Inferencing HTTP server v0.8.4.1\n\n\nServer Settings\n---------------\nEntry Script Name: /structure/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: AppInsights key provided\nInferencing HTTP server version: azmlinfsrv/0.8.4.1\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2023-09-08 12:48:45,601 I [68] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-09-08 12:48:45,609 I [68] azmlinfsrv - Starting up app insights client\n2023-09-08 12:48:48,940 E [68] azmlinfsrv - Traceback (most recent call last):\n  File \"/azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 77, in load_script\n    main_module_spec.loader.exec_module(user_module)\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/structure/azureml-app/main.py\", line 12, in <module>\n    driver_module_spec.loader.exec_module(driver_module)\n  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/structure/azureml-app/score_raman.py\", line 13, in <module>\n    import xgboost as xgb\nModuleNotFoundError: No module named 'xgboost'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/python3.8/site-packages/azureml_inference_server_http/server/aml_blueprint.py\", line 91, in setup\n    self.user_script.load_script(config.app_root)\n  File \"/azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py\", line 79, in load_script\n    raise UserScriptImportException(ex) from ex\nazureml_inference_server_http.server.user_script.UserScriptImportException: Failed to import user script because it raised an unhandled exception\n\n2023-09-08 12:48:48,940 I [68] gunicorn.error - Worker exiting (pid: 68)\n2023-09-08 12:48:49,840 I [11] gunicorn.error - Shutting down: Master\n2023-09-08 12:48:49,840 I [11] gunicorn.error - Reason: Worker failed to boot.\n\nAzure ML Inferencing HTTP server v0.8.4.1\n\n\nServer Settings\n---------------\nEntry Script Name: /structure/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: AppInsights key provided\nInferencing HTTP server version: azmlinfsrv/0.8.4.1\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n/bin/bash: /azureml-envs/azureml_c894f7eb32975bcc312adae58f03236d/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-09-08T12:48:50,025758680+00:00 - gunicorn/finish 3 0\n2023-09-08T12:48:50,033142415+00:00 - Exit code 3 is not normal. Killing image.\n\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694177371987
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AksWebservice, Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.compute.aks import AksCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "\n",
        "aks_target = AksCompute(ws,\"dev-aks2-v1\")\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "\n",
        "network = Model(ws, name='raman_model_nb')\n",
        "scale = Model(ws, name='scale_raman')\n",
        "\n",
        "service = Model.deploy(ws, 'raman-service-v2', [network,scale], inference_config, deployment_config, aks_target)\n",
        "\n",
        "service.wait_for_deployment(show_output = True)\n",
        "print(service.state)\n",
        "print(service.get_logs())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_29953/1480452124.py:12: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(ws, 'raman-service-v2', [network,scale], inference_config, deployment_config, aks_target)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-09-11 03:35:12+00:00 Creating Container Registry if not exists.\n2023-09-11 03:35:12+00:00 Registering the environment.\n2023-09-11 03:35:14+00:00 Use the existing image.\n2023-09-11 03:35:16+00:00 Creating resources in AKS.\n2023-09-11 03:35:16+00:00 Submitting deployment to compute.\n2023-09-11 03:35:16+00:00 Checking the status of deployment raman-service-v2."
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694178790104
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}