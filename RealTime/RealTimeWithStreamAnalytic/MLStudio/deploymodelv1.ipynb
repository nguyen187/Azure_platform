{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1692191104315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "mlv2\nml_group\neastasia\n956a5d16-ed62-4076-890a-4f7ea58eef95\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692191106913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "# Tip: When model_path is set to a directory, you can use the child_paths parameter to include\n",
        "#      only some of the files from the directory\n",
        "model = Model.register(model_path = \"network.h5\",\n",
        "                       model_name = \"operation_model_nb\",\n",
        "                       workspace = ws)\n",
        "\n",
        "model = Model.register(model_path = \"scale.pkl\",\n",
        "                       model_name = \"scale\",\n",
        "                       workspace = ws)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model operation_model_nb\nRegistering model scale\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692164850383
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Create the environment\n",
        "myenv = Environment(name=\"myenv\")\n",
        "conda_dep = CondaDependencies()\n",
        "\n",
        "# Define the packages needed by the model and scripts\n",
        "conda_dep.add_conda_package(\"joblib==1.2.0\")\n",
        "# conda_dep.add_conda_package(\"keras==2.11.0\")\n",
        "conda_dep.add_conda_package(\"numpy==1.24.2\")\n",
        "conda_dep.add_conda_package(\"pandas==1.5.3\")\n",
        "# You must list azureml-defaults as a pip dependency\n",
        "conda_dep.add_pip_package(\"scikit-learn==1.2.1\")\n",
        "conda_dep.add_pip_package(\"scipy==1.10.1\")\n",
        "conda_dep.add_pip_package(\"tensorflow==2.11.0\")\n",
        "# conda_dep.add_pip_package(\"xgboost==1.7.4\")\n",
        "\n",
        "\n",
        "# Adds dependencies to PythonSection of myenv\n",
        "myenv.python.conda_dependencies=conda_dep\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
        "                                   environment=myenv)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692191108199
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AksWebservice, Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.compute.aks import AksCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "\n",
        "aks_target = AksCompute(ws,\"dev-aks2-v1\")\n",
        "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "\n",
        "network = Model(ws, name='operation_model_nb')\n",
        "scale = Model(ws, name='scale')\n",
        "\n",
        "service = Model.deploy(ws, 'operation-service-v2', [network,scale], inference_config, deployment_config, aks_target)\n",
        "\n",
        "service.wait_for_deployment(show_output = True)\n",
        "print(service.state)\n",
        "print(service.get_logs())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_5561/3503029620.py:12: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(ws, 'operation-service-v2', [network,scale], inference_config, deployment_config, aks_target)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-08-16 14:11:58+00:00 Creating Container Registry if not exists.\n2023-08-16 14:12:00+00:00 Use the existing image.\n2023-08-16 14:12:02+00:00 Creating resources in AKS..\n2023-08-16 14:12:03+00:00 Submitting deployment to compute..\n2023-08-16 14:12:45+00:00 Checking the status of inference endpoint operation-service-v2.\nSucceeded\nAKS service creation operation finished, operation \"Succeeded\"\nHealthy\n/bin/bash: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n2023-08-16T14:12:13,934377431+00:00 - nginx/run \n2023-08-16T14:12:13,939773951+00:00 - gunicorn/run \n2023-08-16T14:12:13,947168278+00:00 | gunicorn/run | \n2023-08-16T14:12:13,950384690+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:13,957165315+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-08-16T14:12:13,959206223+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:13,962988536+00:00 - rsyslog/run \nbash: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/libtinfo.so.6: no version information available (required by bash)\n2023-08-16T14:12:13,978878695+00:00 | gunicorn/run | \n2023-08-16T14:12:13,987113726+00:00 | gunicorn/run | \n2023-08-16T14:12:14,006427197+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230509.v1\n2023-08-16T14:12:14,016415634+00:00 | gunicorn/run | \n2023-08-16T14:12:14,024995765+00:00 | gunicorn/run | \n2023-08-16T14:12:14,026542171+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-08-16T14:12:14,028013677+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-08-16T14:12:14,029770383+00:00 | gunicorn/run | \n2023-08-16T14:12:15,543207973+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                      *  /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec\nbase                     /opt/miniconda\n\n2023-08-16T14:12:18,539445139+00:00 | gunicorn/run | \n2023-08-16T14:12:18,546638766+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nabsl-py==1.4.0\nadal==1.2.7\nargcomplete==2.1.2\nastunparse==1.6.3\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.29.2\nazure-graphrbac==0.61.1\nazure-identity==1.14.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.3\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazureml-core==1.52.0\nazureml-dataprep==4.11.7\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.18.7\nazureml-dataset-runtime==1.52.0\nazureml-defaults==1.52.0\nazureml-inference-server-http==0.8.4\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\ncachetools==5.3.1\ncertifi @ file:///croot/certifi_1671487769961/work/certifi\ncffi==1.15.1\ncharset-normalizer==3.2.0\nclick==8.1.6\ncloudpickle==2.2.1\ncontextlib2==21.6.0\ncryptography==41.0.3\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\nFlask==2.2.5\nFlask-Cors==3.0.10\nflatbuffers==23.5.26\nfusepy==3.0.1\ngast==0.4.0\ngoogle-api-core==2.11.1\ngoogle-auth==2.22.0\ngoogle-auth-oauthlib==0.4.6\ngoogle-pasta==0.2.0\ngoogleapis-common-protos==1.60.0\ngrpcio==1.57.0\ngunicorn==20.1.0\nh5py==3.9.0\nhumanfriendly==10.0\nidna==3.4\nimportlib-metadata==6.8.0\nimportlib-resources==6.0.1\ninference-schema==1.5.1\nisodate==0.6.1\nitsdangerous==2.1.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==1.0.1\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work\njsonpickle==3.0.2\njsonschema==4.19.0\njsonschema-specifications==2023.7.1\nkeras==2.11.0\nknack==0.10.1\nlibclang==16.0.6\nMarkdown==3.4.4\nMarkupSafe==2.1.3\nmsal==1.23.0\nmsal-extensions==1.0.0\nmsrest==0.7.1\nmsrestazure==0.6.4\nndg-httpsclient==0.5.1\nnumpy==1.23.5\noauthlib==3.2.2\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\nopt-einsum==3.3.0\npackaging==23.0\npandas==1.5.3\nparamiko==3.3.1\npathspec==0.11.2\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nportalocker==2.7.0\nprotobuf==3.19.6\npsutil==5.9.5\npyarrow==11.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser==2.21\npydantic==1.10.12\nPygments==2.16.1\nPyJWT==2.8.0\nPyNaCl==1.5.0\npyOpenSSL==23.2.0\nPySocks==1.7.1\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\npytz @ file:///croot/pytz_1671697431263/work\nPyYAML==6.0.1\nreferencing==0.30.2\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrpds-py==0.9.2\nrsa==4.9\nscikit-learn==1.2.1\nscipy==1.10.1\nSecretStorage==3.3.3\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\ntabulate==0.9.0\ntensorboard==2.11.2\ntensorboard-data-server==0.6.1\ntensorboard-plugin-wit==1.8.1\ntensorflow==2.11.0\ntensorflow-estimator==2.11.0\ntensorflow-io-gcs-filesystem==0.33.0\ntermcolor==2.3.0\nthreadpoolctl==3.2.0\ntyping_extensions==4.7.1\nurllib3==1.26.16\nwebsocket-client==1.6.1\nWerkzeug==2.3.7\nwrapt==1.12.1\nzipp==3.16.2\n\n2023-08-16T14:12:20,096652922+00:00 | gunicorn/run | \n2023-08-16T14:12:20,103103832+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:20,104994835+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-08-16T14:12:20,106453637+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:20,108123740+00:00 | gunicorn/run | \n2023-08-16T14:12:22,835446583+00:00 | gunicorn/run | \n2023-08-16T14:12:22,837197085+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:22,842023793+00:00 | gunicorn/run | AzureML Inference Server\n2023-08-16T14:12:22,843658295+00:00 | gunicorn/run | ###############################################\n2023-08-16T14:12:22,850269706+00:00 | gunicorn/run | \n2023-08-16T14:12:25,732444289+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-08-16 14:12:26,237 I [12] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-08-16 14:12:26,636 I [12] gunicorn.error - Starting gunicorn 20.1.0\n2023-08-16 14:12:26,637 I [12] gunicorn.error - Listening at: http://0.0.0.0:31311 (12)\n2023-08-16 14:12:26,637 I [12] gunicorn.error - Using worker: sync\n2023-08-16 14:12:26,640 I [69] gunicorn.error - Booting worker with pid: 69\n\nAzure ML Inferencing HTTP server v0.8.4\n\n\nServer Settings\n---------------\nEntry Script Name: /structure/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: AppInsights key provided\nInferencing HTTP server version: azmlinfsrv/0.8.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n/azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\n2023-08-16 14:12:27,665 I [69] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-08-16 14:12:27,673 I [69] azmlinfsrv - Starting up app insights client\n2023-08-16 14:12:30.862524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-08-16 14:12:31.314238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:/azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:\n2023-08-16 14:12:31.314373: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-08-16 14:12:33.834213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:/azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:\n2023-08-16 14:12:33.834487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:/azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:\n2023-08-16 14:12:33.834517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2023-08-16 14:12:35,952 I [69] azmlinfsrv.user_script - Found driver script at /structure/azureml-app/main.py and the score script at /structure/azureml-app/score.py\n2023-08-16 14:12:35,952 I [69] azmlinfsrv.user_script - run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs.\n2023-08-16 14:12:35,952 I [69] azmlinfsrv.user_script - Invoking user's init function\n2023-08-16 14:12:35.975370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:/azureml-envs/azureml_d137506b3aca8565fa06cc9062edccec/lib:\n2023-08-16 14:12:35.975412: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n2023-08-16 14:12:35.975442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (operation-service-v2-6fbd788798-vfnvh): /proc/driver/nvidia/version does not exist\n2023-08-16 14:12:35.975692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-08-16 14:12:37,013 I [69] azmlinfsrv.user_script - Users's init has completed successfully\n2023-08-16 14:12:37,014 I [69] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2023-08-16 14:12:37,014 I [69] azmlinfsrv - Scoring timeout is set to 3600000\n2023-08-16 14:12:37,023 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.26\"\n2023-08-16 14:12:37,031 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.26\"\n2023-08-16 14:12:39,873 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:39 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.26\"\n2023-08-16 14:12:44,873 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:44 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.26\"\n2023-08-16 14:12:45,669 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:45 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"-\"\n2023-08-16 14:12:45,715 I [69] azmlinfsrv - GET /swagger.json 200 0.352ms 2925\n2023-08-16 14:12:45,716 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:45 +0000] \"GET /swagger.json HTTP/1.0\" 200 2925 \"-\" \"-\"\n2023-08-16 14:12:49,873 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:49 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.26\"\n2023-08-16 14:12:50,544 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:50 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"-\"\n2023-08-16 14:12:50,581 I [69] azmlinfsrv - GET /swagger.json 200 0.284ms 2925\n2023-08-16 14:12:50,582 I [69] gunicorn.access - 127.0.0.1 - - [16/Aug/2023:14:12:50 +0000] \"GET /swagger.json HTTP/1.0\" 200 2925 \"-\" \"-\"\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692195171662
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}